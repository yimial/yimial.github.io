{"meta":{"title":"Hexo","subtitle":"","description":"","author":"执杭","url":"http://yimial.github.io","root":"/"},"posts":[{"tags":[],"title":"Lambda 架构","date":"2020/07/07","text":"什么是Lambda架构？Nathan Marz根据他在Backtype和Twitter从事分布式数据处理系统工作的经验，提出了Lambda架构(LA)这个术语，用于通用的、可伸缩的、容错的数据处理架构。LA旨在满足对具有容错性(包括硬件故障和人为错误)的健壮系统的需求，它能够广泛服务于各种工作负载和用例，并且满足了低延迟读取和更新的需求。该系统应该是线性可伸缩的，并且应该向外扩展（横向扩展）而不是向上扩展（纵向扩展）。 所有进入系统的数据都被发送到batch layer和speed layer进行处理。 batch layer有两个功能:(i)管理主数据集(一个不可变的、只追加的原始数据集)，(ii)预计算批处理视图。 serving layer对批处理视图进行索引，以便以低延迟、特别的方式查询它们。 speed layer补偿了serving layer更新的高延迟问题，并且只处理最近的数据。 任何传入的查询都可以通过合并来自批处理视图和实时视图的结果来回答。 组件批处理组件：处理框架 服务组件：合并/低延迟数据库 速度组件：流处理框架、基于云计算的offerings、更多资源（流处理、机器学习、Storm）","permalink":"http://yimial.github.io/2020/07/07/Lambda/","photos":[]},{"tags":[{"name":"比赛","slug":"比赛","permalink":"http://yimial.github.io/tags/%E6%AF%94%E8%B5%9B/"}],"title":"又准备参加比赛（这次要认真走完","date":"2020/03/17","text":"##疫情期间情绪分析比赛 同样研究nlp方向的朋友来找我一起参加比赛，我也正有此意，于是开始着手准备。 前期准备准备参加比赛的时候我的nlp学习进度才进行到acnn……为了能参加比赛，跳级先学transformer、bert等（果然跳级需谨慎）。 transformer学习（3.15-3.17）这个我是直接看的论文，很多地方没看懂，于是看了一个超级简单的代码，代码省略了很多细节，又看了一篇朋友推荐的博客才看懂想研究BERT模型？先看看这篇文章吧！对所谓seq2seq有了一些了解，之前师兄一直说到的transformer原来是这样的。 bert学习（3.17-）从下文开始入门的bert，上来就点进去第一个链接看了bert的github。。。。。。没看明白。。。。。 一文读懂BERT(原理篇)于是还是打算从下面的blog结合论文和最简单的代码开始看吧 Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing从以上找到几个不错的代码，下面这个可以用于情感分析 BERT实战，多标签文本分类，在 AI Challenger 2018 细粒度情感分析任务上的尝试下面这个是不是可以为我毕设所用嘿嘿嘿 BERT实战，命名实体识别 BERT实体与关系抽取看完了论文和blog，发现官方源码看不懂，于是找了一些csdn和知乎上的讲解 bert的使用 bert的花式改进没有TPU的时候可以把tpu改成gpu 代码简化这个代码给了我启发，我是不是也可以用bert的预训练结果用于训练lstm-attention等网络，然后再做xgboost CCF-BDCI2018 汽车领域ASC挑战赛","permalink":"http://yimial.github.io/2020/03/17/Competition/","photos":[]},{"tags":[{"name":"毕业","slug":"毕业","permalink":"http://yimial.github.io/tags/%E6%AF%95%E4%B8%9A/"}],"title":"毕业论文从开题后到完成全不记录","date":"2020/02/03","text":"寒假在家本来打算寒假回家玩四五天就要开始认真学习的我到现在还在每天学三个小时玩八个小时的状态，因为疫情的关系，假期延长了，更不能再浑浑噩噩下去了。之前每天在看的是Stanford2017的自然语言处理课程在b站上的中英版（小声bb：后期的中文翻译看得我痛苦不堪），一个半小时不到的课我每次都要看三个小时以上（包括崩溃装死的时间），若一天的其他时间再去学别的东西我可能会从此厌学一蹶不振，于是打算其他的时间用来做一些实验，实现一些简单的代码为以后毕设做准备。现在暂时学了word2vec、词分类和RNN，就先依次down一些代码数据做一些实验好了。 跑简单代码（2.7-2.17）跑了几个超级简单的baseline，记了笔记在onenote中，最重要的是花了两三天的时间改了改attention+seq2seq的代码，把只有一个训练样本的代码加了个训练样本，看起来改动不大，着实费了老鼻子劲，也发现源代码很多的问题，通过这一个简单的改进，也更加了解了这个代码的实现细节。 跟着知识图谱实现课程做实践（2.18-2.20）44看了师兄推荐的一个知识图谱实现课程，学到了一些些东西但感觉讲的不太好，感觉真的重点难点没听懂，发现这种方法不如自己下代码一行行读来的快和方便，于是放弃 实现一些类似论文的知识图谱实现阅读类似论文（2.21-2.23）找了一堆lstm+cnn+远程监督的论文，其中意外下到一篇2019的论文《深度学习实体关系抽取研究综述》，20多页讲的忒详细，打算花一天时间好好看看，里面提到了70多篇论文，有中文有英文，我打算就靠这篇综述扩展我的论文阅读量啦，捡到宝。实体关系抽取 entity relation extraction 文献阅读总结 Python自然语言处理工具NLTK学习导引及相关资料 NLP工具——stanford Parser使用手册斯坦福大学 深度学习与自然语言处理 笔记 深究这篇宝藏论文中提到的我感兴趣的技术（2.24-）跑了几个经典论文的代码：Rocher、Zeng等，并理解了论文提到的实现细节。同时了解了pytorch和tensorflow的基本使用。期间也遇到了怎么实现都无法复现的论文，花了四五天，很迷惑。。。。我打算之后把每天做的事做一个简单计划和小记，免得我老忘记我这几天死哪去了。。。。。。中间学到lstm后就分叉去看bert了 项目相关2月底的时候老师终于跟我说项目定下来了，就做《人工智能技术成果与应用转移转化知识图谱及应用平台》，前期主要工作是做数据收集和知识抽取。 于是暂时列个计划书来安排这个项目吧！ 3月初老师给我发了两个文件，都是关于人工智能在国内的发展的，可用于以后收取数据和图谱建模作为参考 比赛相关（3.12-）为了更好地学习nlp，和好姬友一起参加了一个比赛做情绪分析的，之后会花一部分时间在这个比赛上。 在这个过程中又参加了一个实体抽取+关系抽取的竞赛，打算用bert试一试，于是搜到一个相关代码，它的实现思路是对于这种端到端的方法，先抽取存在的关系，再进行槽填充，我个人觉得是个办法。之后好好探索一下。2019语言与智能技术竞赛信息抽取任务解决方案 卧槽卧槽！！！！百度的比赛是关系抽取的！！！！啊我想放弃这个情绪分析去做那个了怎么办啊！！！！！他还给了好多关系抽取标记数据我飞了！！！近日最大收获啊啊啊！！！！！！！我可能要转移重心了，反正我好姬友中途有事我们已经好几天没相互联系了。。。。。。 加入组会（4.13-）因为参加了比赛的原因，被同学的导师允许加入他们的组会以后一起汇报学习，这样的话就应该更有计划地学习，免得组会的时候尴尬。。。。。。 好的博客（4.17-）利用关系抽取构建知识图谱的一次尝试","permalink":"http://yimial.github.io/2020/02/03/graduate3/","photos":[]},{"tags":[{"name":"毕业","slug":"毕业","permalink":"http://yimial.github.io/tags/%E6%AF%95%E4%B8%9A/"}],"title":"行业知识图谱构建从小白到毕业——流水账式不全记录","date":"2019/12/01","text":"定题2.0找过导师谈过以后，加上自己之前想做的方向，重新决定了研究方向：知识图谱+hadoop大数据处理技术 知识图谱入门之前听过一个电台，有个行业大佬推荐了王昊奋老师的知识图谱课程，于是从王老师的课程开始入门。听课的过程挺痛苦的，让我想起了被“听不懂”支配的研一一年。但是通过一遍一遍地听、听不懂的去百度还是学下来了。因为我目前只需要做到构建出一个行业知识图谱的步骤，所以听到第六课“知识融合”后面就没听了。王老师的课还是挺经典的，覆盖面也很广，让我对构建知识图谱的整个流程和相关工具和技术有了一些认识，后来看到各种各样的专有名词的时候也亲切了一些。 大致规划在知识图谱的构建流程中：知识抽取、知识挖掘、知识存储、知识融合（还有整体的流程架构也许也是一个方向），我把最不感兴趣的知识存储排除在外，直觉告诉这个方向我没什么好研究的，很多技术拿来就用就行了。除了以上流程，前后期还有几个操作步骤：数据库的选择、数据模型的制定、爬取数据、数据可视化。确定大致步骤以后就是通过初步的实验进一步了解自己要研究的东西，实验的过程中卡在哪就从哪开始学。 一些简单想法 在看各种各样的博客的过程中，我时不时有一些简单的想法，记录在下面：1. 做一个实时增量的知识图谱，可实时融合新的数据，但这个新的数据通过什么方式输入系统是个问题；新旧知识的取舍也是个问题，实体链接、本体对齐和置信度。2. 为了能和spark等大数据处理技术融合，希望尽量使用机器学习的技术（和需求驱动的思想相违背了，但是毕竟是为了提升自己）3. 面向主题的知识图谱，方便不同业务人员的操作4. 使用树结构来表示句子，可通过剪枝的方式缩写句子再向量化进行相似度对比，还可以和基于模板的方法结合5. 半监督和集成学习、joint方法还有很多可研究的 查找资料查找资料的过程中掉入了很多的坑，有的坑深有的坑浅，有的坑是个地道捷径，有的坑爬出来还在原点 坑1：想导入一个开源知识图谱到Neo4j中看看效果我看到openkg中有的数据是json格式的，就找了很久怎么把json文件导到neo4j中转化成知识图谱，后来发现，json格式本来就是一种知识图谱的序列化格式，我追求的只是它的可视化而已…… 知识图谱说的是一种数据模型，它的存储方式有很多种，图数据库也并不是存成一个图，neo4j也只是提供了图数据的可视化而已。数据的真实存储方式还是序列化的。可视化使得我们能够直观地看到数据库的规模、内容等，仅可以作为一个展示和检验评估的工具，而不是判定这个数据是不是图数据的标准。让我们反推一下，想要得到可视化效果，首先要得到csv文件，要得到怎样的csv文件呢？我发现我对Neo4j一无所知。我需要好好学一下Neo4j。 坑2：我又看到一篇博客Eastmount的知识图谱实战篇文中提到星球系列电影这个课程。嗯？好东西！我以前怎么没想到会有这样的课程呢？自己琢磨能琢磨出啥，我又不是大佬…… 坑3：找到了非常类似的项目虽然这个课程偏重于可视化不是我要的课程，但是这个给了我一个启发，我在b站和网易云课程上又搜了一下知识图谱的实战课程，发现一个汽车知识图谱实战项目课程，在它的评论中看到一条评论说这个是仿照他们做的农业知识图谱做的但是只是改成了汽车的，我又点进那条评论给的github网址……我！的！马！鸭！“…上海市…《上海农业农村大数据共享服务平台建设和应用》…构建面向智慧农业的知识图谱及其应用系统…”这就是我要找的！ 坑4：找到了非常好又基础的知识图谱课程（12.4-12.5）汽车知识图谱那个太偏实际使用化，完全没有我想要获取的知识。于是我在某站上按“知识图谱”搜了一下实战课程，找到了一个一百多节课的课程，其中讲算法老师讲的很好，声音又好听，我很少遇到我听了不开小差的课，这就是其中之一。我选了其中的算法和理论课程听完后，觉得受益匪浅，这个坑跳得值。 坑5：看前沿论文（12.7-12.10）我知道光看课程是不够的，实战课老师毕竟讲的还是已经普遍流行了的算法，老师对我的帮助又有限，我需要看一些前沿论文才不至于研究别人已经研究出来了的东西……为了加快进程，我决定先选近两年的综述类文章看。看了几篇综述类文章后，我清晰地认识到在听课的过程中我脑海中想到的方法基本早就被别人研究过了……嗯，暂时只有这些沮丧的收获。再加上最近迷上健身，晚上学习的时间从四个小时缩减成两个小时 定题和开题报告ppt制作(12.10-1.3)已经12.10了，中下旬就要开题，再不开始做ppt实验和报告就可以直接辍学去挣钱了，为了让自己穷下去，我总结了一下目前已知的知识感兴趣的方向和遇到的问题，初步定了个题目：《基于半监督学习的领域实体关系抽取方法》（我对半监督学习真的是情有独钟……）。 我从师姐那里要来了开题报告的规定提纲，准备一个标题一个标题来准备以及阅读论文。 1、 选题的背景及意义 王昊奋第1课、第11课ppt 说清楚要解决什么问题，知识图谱的重要性，行业知识图谱的重要性，关系抽取的重要性 2、 国内外本学科领域的发展现状与趋势3、 课题主要研究内容、预期目标4、 拟采用的研究方法、技术路线、实验方案及其可行性分析5、 已有研究基础与所需的研究条件6、 研究工作计划与进度安排7、 参考文献 要求：既不要让老师觉得你在给他讲课，又要让老师比较简单地get到我在说什么。 坑6：科学知识图谱在找论文的过程中，我看到了一个名词：科学知识图谱，好像和我要做的东西很像，我之前居然一直不知道这个名词的存在，后来一看维基百科，并不一样：科学知识图谱。 坑7：开放域知识图谱我不知道从哪里又看到一个开放域知识图谱的概念，2007年提出的好像有的研究，我屁颠屁颠的了解了一下，发现开放域和领域是平行的……那可是半监督就是开放域关系抽取的方法之一啊，那半监督还能用来搞领域知识图谱吗？ 坑8：知识融合看各种论文的过程中，我感觉知识融合好像很有的研究，再加上我发现三元组要变成知识图谱是一定要经过知识融合这一步的，而且我想做的增量更新也是知识融合的部分，然后开始纠结要不要改方向改成知识融合……因为研究了这么久突然想改导致我很烦躁，烦躁了一个周末以后，周一晚上勇敢面对问题开始找知识融合的论文看，然后一个晚上就被劝退了。。。。。我比较熟悉的机器学习的方法在知识融合中基本已经过时了，现在大部分是在用知识表示的方法，这方面数学公式超多，要求比较高的数学功底（而且李攀成的《公共安全领域知识图谱的知识融合技术研究》把我想到的没想到的方向和内容都研究的明明白白，我还看不懂……我干嘛，何必呢），我……死心了 结论最后终于还是把题目定下了：《基于深度神经网络的领域关系抽取方法及其实现》，还没给老师看过，估计要改。制作ppt的过程太投入忘记记录博客了，大概就是先把自己要说的话写了个演讲稿，再根据演讲稿制作的ppt，第二部分发展现状看了一些论文，其中有一篇叫《基于深度学习框架的实体关系抽取研究进展》真的是神仙下凡，把近年的关系抽取上深度学习方法的发展讲的明明白白完完整整，我从这篇论文出发大致看了一下提到的一些论文，了解了一些较为前沿的方法和方向，最终才定下的这个题目。 论文调研突然被通知我们实验室要先交开题报告word版……没事开题时间定在1.10还有时间，我开始从之前写的演讲稿开始扩展编辑开题报告，刚开始很抗拒，第一章卡在方向问题上一个字也编不出来……后来慢慢想开了，先用白话写了一些再慢慢改成书面语就会轻松一些。第二、三、四章很轻松，得益于之前写的演讲稿直接复制粘贴扩展毫无压力。第五章我就蒙了，我哪有什么研究基础，也不知道自己需要什么研究条件也不敢随便提……这里我先跳过第五章决定和老师聊过再写。第六章我再次懵逼……我之前看论文都只看他们用了什么模型但是没看细节，对工作流程我一窍不通，于是决定看一下这些论文的实现细节。之后，才完成了开题报告的初步写作。 项目调研(1.3-1.5)写好了开题报告后，因为之前老师跟我说的项目还没定下来，于是去找导师问了问，顺便拿开题报告给导师看，导师说之前申请的项目还没有定下来，但是开题报告上要写上落地项目，而我恰巧知道公司有个项目是用到知识图谱的，我有个师兄刚好在做，于是提出问问那个师兄关于这个项目的事。 项目纠结通过师兄了解了这个项目，各方面都挺适合我的，这个项目分两期，一期接触到了我以后想要从事的大数据存储与处理技术，二期是基于一期已完成的基础上建设的，需要构建一个知识图谱，还需要用到深度神经网络进行图像识别，而且师兄还一直跟我强调包吃住还有一天一百，一切看起来都太完美了。但是，这反而令我不那么放心，因为师兄，太热情了，我发一条他回五条，让我有一种浓浓的传销既视感……之后看过师兄发给我的合同，我逐渐明白这种既视感来自哪里： 大数据处理方面我的同事最近已经在学了，之前师兄说过他不愿意做这一部分，很可能这部分不是我师兄在做，而是我公司的同事在做，那我跟着师兄去出差可能会反而接触不到这些技术； 师兄说他跟着美国芝加哥谷歌团队的一个学生在做，什么意思，这个人带着我师兄在做，我师兄又带着我做，那分配到我手上的工作是不是已经很不核心了； 动态特征选择很符合我，但是他们用的是事件聚类，主要是舆情应急处理系统用到知识图谱这一方面，主要是做事件追踪，是不是做事件抽取的？ 我们到底是一期还是二期 师兄是做开发还是实施啊？知识图谱还是图像识别？现阶段有没有开始这个项目啊？我不会又把自己送去做实施了吧……这个项目还有很多的业务系统，我不想做，我可以不做吗，等我到了贵州，我可以做我想做的事吗，到那个时候我再说辞职，还来得及吗 知识图谱并没有和深度学习结合，深度学习是用来做图像识别的，也有道理，深度学习用在知识图谱，可能他们觉得没这个必要，很可能用的是很基础的模板匹配…… 师兄说一天100，一月30天，为什么呢，难道周六周末也要上班吗？加班情况如何，我有时间写自己的论文吗，还有那边有女孩子吗…… 基于这些问题，我打算先看一下师兄之前要下的论文，再问一下师兄。 知识图谱将用到哪些技术们能不能用到深度学习，不会就是评论转发两种关系吧，那和我的论文完全没关系，而且我也没时间改了 我能不能接触到大数据处理 什么谷歌的学生 师兄主要负责哪一块，知识图谱还是图像识别？还是业务系统还是实施？我去了以后是跟着做这一块吗 加班情况 问过以后，我还真的不想去了……总而言之最终和师兄说了我不去。 正式开题(1.7-1.10)背了几天演讲稿，开题那天还是没有做到很满意，还是在死记硬背好像没有做到流畅的信息输出，反观师兄师姐他们的汇报就很自然（有一个老师，举手投足之间都很像我爷爷，而且他说话也很有学者的感觉，还很谦逊，被圈粉^.^）。老师们给了我一些建议，主要有两点： 题目需要体现知识图谱 需要更多的文献调研，说清楚他们的方法有什么问题，我的工作有什么意义，而不是撞别人的优点上 我打算，在放假之前再好好看看论文，把开题报告再改改。放假之后好好学hadoop、spark、kafka等，为什么要学这些呢，我有预感明年项目组可能会接触到这些。（后来我同事跟我说我所在的项目组并没有这方面的能力，我上司的意思是让我一个人做试试看，我的同事还建议我出去找实习，但是我的导师不让我们自己出去找实习，所以我之后可能还是会辞职，要早日开始练习笔试和code了……） 调整开题报告(1.12-1.15)老师之前给过我一个建议，看看深度学习有什么在别的领域使用过的方法，引入到关系抽取领域中，深度学习有哪些方法我都忘了，这几天看的又都是有关关系抽取的论文，于是我打算这几天看看研一学的深度学习课件，可能会有所启发吧。再把别人方法的缺点和没解决的问题整理一下，在这个基础上去做我自己的工作。 看PPT的过程中其实脑子里跳出来很多想法，但是心理阴影告诉我很可能别人已经做过了，所以我有必要花时间把所有关系抽取相关的论文都找出来看，尤其是每个我想引入的方法被提出以后发表的。 看完以后发现了几个想法：RCNN的联合训练思想、胶囊网络、k-means、PCA降维特征向量。其中胶囊网络比较新，而且它的思想也很适合做关系抽取，但之前已有人做过了，而且我改了论文交上去，导师建议我不要做，说硕士做胶囊网络有难度，于是又改回LSTM和CNN，只说要做联合训练。 到此，开题报告就结束了。","permalink":"http://yimial.github.io/2019/12/01/graduate2/","photos":[]},{"tags":[{"name":"毕业","slug":"毕业","permalink":"http://yimial.github.io/tags/%E6%AF%95%E4%B8%9A/"}],"title":"毕业论文从一片迷茫到完成不全记录","date":"2019/11/17","text":"2019-11-17开始记录： 前情提要（三个月8.4-11.8）：因为导师是处于放养型的，所以很多东西都需要自己摸索。刚从集中教学回到研究所的时候，什么情况都不清楚，能力又不行，平时又不怎么看行业动态，除了研一学了一些人工智能和大数据的很简单的专业知识以外，和我一年前刚跨专业考进来时一样小白，长时间熬夜的生活习惯导致脑子又不好使，理解能力反应能力都差。（如果看者之后看到某一段而有“一个研究生这都不懂？”的疑问，答案参照这一段，总而言之就是因为我当时蠢；如果某个地方的概念理解偏差或者名词用错了之类的，欢迎吐槽纠正，阿里嘎多！） 来了研究所以后有找导师谈过一次话，导师说了很多，我都记在本本里了但是没几句真的明白导师想说些什么的，似懂非懂。后来导师推荐我去研究所的公司的一个项目组实习，我代码能力很弱，javaee都要从javase学过，所以在项目组学了一段时间的javaee和mongodb（除了集群和复制集部分，项目组目前没有使用到这一块就让我先不学），中间两次被派去写文档、数据录入等，我不想去但是因为项目组给我面试的时候有说过可能会安排我去做实施所以我没提出异议。直到开题通知下来，十二月份开题，我依然是刚回研究所的懵哔状态，我觉得这样下去不行，于是和项目组的人提出调回开发组…… 渐渐清醒（七天11.9-11.15）：在开始准备开题之前，我晚上的时间依然会用来学javaee，因为我想快点学完快点上手，但是准备开题之后，晚上时间我开始看论文、行业动态、岗位任职要求、知乎上的问题等等。我是大数据处理研究生，在网上看到一篇文章，是关于大数据的100篇入门论文的，我花了四天晚上的时间看了其中的两篇关于大数据架构的博客，分别是讲lambda和kappa的。结合翻译软件我看的还挺顺利的，开始自信爆棚。看完这两篇博客后，接下来的论文动辄16页以上，我找不到网上的翻译，就打退堂鼓了。因为我不打算转博嘛，我读研的最终目的也是为了更好地工作，于是我逃避论文之余开始看起了大数据开发岗的任职要求…… 看了一个晚上的工作内容任职要求和知乎，并不是没有收获，我从我心仪的公司（以后称呼它Y公司）的招聘信息中看到他们招图像识别文本挖掘的算法工程师和大数据开发工程师。由此得出两个开题方向，NLP和“把大数据现有技术应用在某个领域”，一个对应算法岗，一个对应开发岗。后来向算法岗迈出的脚趾甲被劝退，理由可想而知，再加上Y公司的title是大数据，我毕业的时候他指不定是不是不搞图像和NLP的算法了……然后在我看到的各种各样的信息中渐渐明白了开发岗到底是干嘛的……回到寝室以后和同一届的同门交流了一下，我同门比我拎得清多了，他建议我把论文和所在项目组的项目结合起来，等等等等。一个晚上感觉想明白了很多事情：我意识到我在这里不是来工作的，是来学习的。导师之前跟我说的一些话我好像也琢磨出了其中的用意和背后蕴含的信息。最重要的是，我搞明白了我为什么要继续呆在这个项目组，我意识到项目对论文的重要性，我之前还想着要辞职，现在也不想辞了，没人带我我就得自己主动利用现有的资源，主动找事做，化被动打工为主动利用资源。除此之外，我意识到我并不是员工，又没有工资，我没啥好害怕失去的，最理想的状态应该是能在这段时间搞清楚一个项目的流程，从中找到我论文的切入点，如果能够给项目带来一些优化就更好，如果不行的话，那么导师给我的自由反而就成为了一件好事，我不必为项目所束缚。我为我琢磨清楚这些感到很高兴，也不觉得自己几天没看论文是多么浪费时间的一件事了，从一个菜鸡研究生的“自闭”之路清醒出来。 开始定题选题纠结1.0（一天 11.16）：我又通过看一些博客、知乎、任职要求明白开发有两个方向：利用大数据的工具做应用程序的开发、在现有大数据开源工具上做二次开发。我列了一下这两种方向的步骤，第二种明显更有技术含量，也更好写论文，而且写论文的过程中，第二种其实可以结合第一种，针对项目做二次开发什么的就更好了。我也知道自己水平有限，真的要做什么二次开发很可能会失败，但我不想只是下一个源码会跑就行根本不会改，在此立个flag，如果最后我真的是这样收尾，这篇博客我就隐藏掉不发出来（没脸发……）此时的我还很天真，对毕业论文的程度和二次开发一点概念也没有定了这个方向以后，我又开始琢磨我现在所在项目组的项目们，好像是在给政府做报表系统，数据收集数据存储数据处理数据可视化，我觉得很好，因为我以后如果进不了Y公司，能进银行是我的次选择，我觉得这就很对口，于是决定了题目就是把报表系统和大数据相结合（后来才知道这其实就是BI）。到此，我结束了我来研究所以后三个月的迷茫懵哔状态，但小白还是这个小白。 开始评估选题的可行性（四天 11.17-11.20）我针对开题定了几个步骤： 看大数据系统相关的论文，深入了解各个组件的特性和原理 看报表系统应用大数据技术的论文，一方面是看看做这个的都做到什么程度了，一方面是给自己的论文打个样 follow一些大数据处理工具的源码以及步骤1中论文的源码 follow一些报表系统应用大数据技术的源码 找到一个针对报表系统的某种需求可改进的点，架构上的或细节上的并逐一确保这个流程能否顺利完成：1是OK的，毕竟有那100篇论文。2也是ok的，我找到一些报表系统项目和大数据处理技术结合的论文了。3是ok的，因为有很多比如HBASE、mapreduce这样的开源项目.第四步有点困难，我直接搜报表系统hadoop源码并没有搜到，后来我看到了BI这个词，对于理解BI的定义这个过程，那叫一个曲折婉转……总而言之就是花了三天的时间研究BI到底是个什么东西（中间我借机问了一下同事我们公司的可视化页面怎么做的，发现这一部分他们是买了一个组件，由那个组件来完成的，我点开卖这个组件的公司主页，从这个公司的主页信息中也获取到了一些信息）。BI是集数据仓库、数据挖掘、OLAP、可视化为一体的一个解决方案…吧。第五步我是在白天的工作过程中慢慢进行的，录数据的时候发现了系统的什么不合理的地方我就记在小本本里，以供以后慢慢挑选，第五步必须能完成，因为需改进的点太多了。 选题纠结2.0我在网上看了一些优秀硕士毕业论文，发现主流的毕业论文主要分为两种：基于某某的某某系统设计与实现、某某算法的研究，开发岗对应第一种。翻阅别人的毕业论文的过程中，我终于回忆起自己在本科毕设指导老师的指导下是怎么写毕业论文的。第一类毕业论文一般都基于自己的毕业设计，介绍一下相关技术、分析一下用到的算法和对算法的改进、介绍一下各个模块的设计与实现等。这类论文又分两种：偏实际开发的，有实际的需求分析等，偏整体实现；在系统架构中针对某个细节做自己的创新的，偏细节研究。到这里我打算先去和老师谈谈，看老师怎么说再做决定。 见老师前准备去和老师谈之前，我做了一些准备，我模拟老师会问我的几个问题，并尽可能地想好了回答。为什么想选这个题 有什么初级的解决方案没有 需要什么硬件支持 最后一个是最魔鬼的，上次让你看的Neo4j你看没看 见老师后老师上来就问了我最后一个问题，后来我从跟老师的交流中得出他之前的意思是让我研究知识图谱，论文也写这方面的……到此，这篇博客走到了它的尽头，我要重新开始新的一轮规划了","permalink":"http://yimial.github.io/2019/11/17/graduate1/","photos":[]},{"tags":[{"name":"Lambda 大数据","slug":"Lambda-大数据","permalink":"http://yimial.github.io/tags/Lambda-%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"title":"Questioning the Lambda Architecture阅读笔记（翻译）","date":"2019/11/12","text":"Lambda架构有其优点，但值得探索其他替代方案。作者先介绍了一下Lambda系统，它的优点、缺点，以及替换方案 一、引言Lambda架构是在MapReduce和Storm或类似系统上构建流处理应用程序的一种方法。 其工作方式是捕获不可变的记录序列并并行地输入批处理系统和流处理系统。需要两次实现转换逻辑，一次在批处理系统中，一次在流处理系统中。在查询时将来自两个系统的结果拼接在一起，以生成完整的答案。 Lambda系统：一个记录序列同时输入两个系统，批处理系统隔一段时间统一预计算一次，实时系统及时进行增量计算，当某一段记录在批处理统一计算时经过了批处理系统，即可在实时系统中删除这些记录的结果。查询到来时，将批处理视图和实时视图直接拼接合并就是最新的数据。批处理视图存在HDFS中，实时视图存在HBase中，拼接后使用可以在这两个存储系统上查询的Impala进行查询 这其中还可以有一些变化，比如换掉Storm、Kafka和Hadoop。人们通常使用两个不同的数据库来存储输出表，一个用于优化实时处理，另一个用于优化批量更新。 Lambda架构可用于处理那些围绕复杂的异步转换构建的应用程序，这些转换需要以低延迟运行(例如，几秒钟到几小时)。比如新闻推荐系统，它需要抓取各种新闻来源，处理和标准化所有的输入，然后建立索引、排序，并将其存储以供服务。 Jay Kreps认为这种方法并不是处理实时数据的最好的方式，并列出了一些优缺点 二、Lambda的优点输入数据的不可变性：把data transformation看成从输入数据出发的一系列实例化阶段是非常好的。这是使大型MapReduce工作流易于处理的原因之一，因为它使您能够独立地调试每个阶段。Jay Kreps写了一些关于捕获和转换不可变数据流的想法。 数据reprocessing：数据reprocessing是流处理的关键挑战之一，但常常被忽略。代码总是会改变的。因此，如果您有从输入流派生输出数据的代码，每当代码更改时，您都需要重新计算输出以查看更改的效果。有很多原因会造成修改代码，不论为什么要修改代码，你都需要重新生成你的输出，我发现，许多构建实时数据处理系统的人并没有在这个问题上花太多心思，最终导致系统无法快速发展，因为没有方便的方法来处理reprocessing。Lambda体系结构强调了这个问题，值得赞扬。 Lambda架构的提出还有一些其他动机，但是我认为它们没有多大意义。一个是实时处理本质上是近似计算，比批处理更弱，误差更大。我认为不是这样。确实，现有的流处理框架集不如MapReduce成熟，但是没有理由证明流处理系统不能提供与批处理系统一样强大的语义保证。什么叫做强大的语义保证，是指向实时处理并不是一种近似计算吗？为什么有人说实时处理是近似计算？如何证明实时处理不是近似计算？ 还有另一种解释是Lambda架构通过使用不同的权衡混合不同的数据系统，以某种方式“击败了CAP定理”。长话短说，虽然流处理中确实存在延迟/可用性权衡，但这是异步处理的体系结构，因此计算的结果不会立即与传入数据保持一致。遗憾的是，CAP定理仍然未被打破。为什么异步处理的体系结构计算的结果不会立即与传入数据保持一致？我看着挺一致的啊？ 三、Lambda的缺点Lambda架构的问题在于，需要保持两个复杂的分布式系统会生成相同的计算结果，这就像听上去这么痛苦。Jay Kreps认为这个问题解决不了。在Storm和Hadoop这样的分布式框架中进行编程非常复杂。代码会被构建成相应框架的形式。实现Lambda架构的系统的操作复杂性似乎是每个人都一致同意的。 为什么不能改进流处理系统来处理其目标域中的所有问题？解决此问题的一种建议方法是使用一种语言或框架，该语言或框架对实时和批处理框架进行抽象。开发者使用这个高级框架来编写代码，然后它“向下编译”以进行流处理或MapReduce。Summingbird就是这样一个框架。这确实让事情好转了一点，但我不认为它解决了问题。 最后，即使可以避免对应用程序进行两次编码，运行和调试两个系统的操作负担也会非常大。任何一个新的抽象都只能提供这两个系统的交集所支持的特性。更糟糕的是，使用这种新的超级框架隔离了使Hadoop成为如此强大的丰富的生态系统的工具和语言(Hive、Pig、Crunch、Cascading、Oozie等)。 使跨数据库ORM真正透明是很困难的。和对那些非常相似的使用标准化的接口语言提供几乎相同的功能的系统进行抽象的问题相比，在几乎不稳定的分布式系统上构建的完全不同的编程范例是非常困难的这一段没懂，什么是透明，什么是跨数据库ORM，这一段从哪里来，要到哪里去 四、作者的工作Jay Kreps在LinkedIn做了很多尝试，混合Hadoop架构甚至是一个特定领域的API，它实现了Hadoop层和实时处理层的透明化。但是这些方法都没有令人满意。隐藏底层框架的方法被证明是最有漏洞的。它最终还是需要深入了解Hadoop知识以及实时层的知识——除此之外还增加了一个新要求，即无论何时要调试或计算性能时，您都要非常了解如何将API转换为这些底层系统。 所以Jay Kreps的建议是，如果您对延迟不敏感，可以使用批处理框架(如MapReduce)，如果您对延迟敏感，可以使用流处理框架，但不要尝试同时进行这两种处理，除非您必须同时进行。 那么，为什么Lambda架构如此令人激动呢?Jay Kreps认为原因是人们越来越需要构建复杂的、低延迟的处理系统。他们手头有两个不能完全解决的问题:一个可伸缩的高延迟批处理系统可以处理历史数据，一个低延迟流处理系统不能reprocess结果。通过管道把这两个东西粘在一起，就建立了一个有用的解决方案。 在这个意义上，即使Lambda架构是痛苦的，它依然解决了一个通常会被忽略的重要问题。但Jay Kreps不认为这是一个新的范式或大数据的未来。它只是被现有工具的限制所驱动的一个临时状态。Jay Kreps认为有更好的选择。 五、替代方案作为一个设计基础设施的人，Jay Kreps认为最突出的问题是:为什么不能改进流处理系统来处理其目标领域的所有问题?为什么需要粘在另一个系统上?为什么不能同时进行实时处理和处理代码更改时的reprocessing?流处理系统已经有了并行的概念;为什么不通过增加并行度和非常快地重放历史来处理reprocessing呢?答案是，你可以这样做，我认为这实际上是一个合理的替代架构，如果你正在构建这种类型的系统。 当我与人讨论这个问题时，他们有时告诉我，流处理不适合于处理高吞吐量的历史数据。但我认为这种直觉主要基于他们所使用的系统的局限性，这些系统要么伸缩性很差，要么无法保存历史数据。这让他们有一种感觉，流处理系统本质上是计算一些短暂流的结果，然后丢弃所有底层数据的东西。但没有理由认为只能这样。 流处理中的基本抽象是数据流DAGs。DAG与传统数据仓库(la Volcano)中的底层抽象概念完全相同，也是MapReduce后续Tez中的底层抽象概念。流处理只是这个数据流模型的概况，它向最终用户公开中间结果的检查点和连续输出。为什么说DAG和传统数据仓库底层抽象概念完全相同？这一段又是想说明什么？ 那么，我们如何直接从流处理工作中进行reprocessing呢?Jay Kreps喜欢的方法其实非常简单:1.使用Kafka或其他系统，可以保留您希望能够重新处理的、允许多用户访问的数据的完整日志。例如，如果您希望重新处理最多30天的数据，请将Kafka的保留时间设置为30天。2.当您要进行reprocessing时，启动流处理job的另一个实例，该job从保留数据的开始处开始处理，但将此输出数据定向到新的输出表。3.当第二个job完成时，将应用程序切换为从新表读取。4.停止旧版本的job，并删除旧的输出表。 那30天以前的数据呢？就不管了吗与Lambda架构不同，在这种方法中，您只在处理代码更改时进行reprocessing并重新计算结果。当然，重新计算的job只是相同代码的改进版本，运行在相同的框架上，使用相同的输入数据。您会希望提高reprocessing job的并行性，以便它能够非常快地完成。 也许我们可以称它为Kappa架构，尽管它太简单以至于只值得一个希腊字母。 撤回功能当然，您可以进一步优化它。一般情况下，您可以合并两个输出表。Jay Kreps认为有必要在短时间内同时拥有两者。这允许您通过一个将应用程序重定向到旧表的按钮来立即恢复到旧逻辑（撤回）。在特别重要的情况下(比如，您的广告目标标准)，您可以使用自动A/B测试或bandit算法来控制切换，以确保与之前的系统相比，您正在推出的任何bug修复或代码改进不会意外地降低性能。 HDFS和Kafka集成请注意，这并不意味着您的数据不能存到HDFS;这只是意味着你不会在那里进行reprocessing。Kafka与Hadoop有很好的集成，所以将任何Kafka主题镜像到HDFS中都很容易。可以将流处理作业的输出流甚至中间流用于Hadoop中的分析工具(如Hive)，或者用作其他离线数据处理流的输入。 我们已经使用Samza实现了此方法以及其他reprocessing体系结构的变种。 六、一些背景（Kafka）对于那些不太熟悉Kafka的人来说，我刚才所描述的可能没有意义。快速复习一下可能会把事情弄清楚。Kafka保持这样的有序日志:知道你不早说Kafka的“主题”是这些日志的集合： 使用此数据的流处理器只维护一个“偏移量”，即它在每个分区上处理的最后一条记录的日志条目号。因此，更改使用者的位置以返回并重新处理数据非常简单，只需使用不同的偏移量重新启动作业即可。为相同的数据添加第二个使用者只是 添加 另一个指向日志中不同位置的读取器。不管偏移量在哪，日志文件保持近三十天的内容不变，重启作业时，改作业顺着日志走到头。 Kafka支持复制和容错，运行在廉价的普通硬件上，并且很乐意在每台机器上存储很多TBs数据。因此，保留大量数据是一种非常自然和经济的做法，不会影响性能。LinkedIn在网上保留了pb级的Kafka数据，许多应用程序都很好地利用了这种长时间的保留模式。 廉价的消费和保留大量数据的能力使得添加第二个“reprocessing” job仅仅是启动代码的第二个实例，只是要从日志中的不同位置开始。那日志没有保存的操作就不用重新执行了吗刚好就很适合做流处理的reprocessing这个设计不是偶然的。我们构建Kafka的目的就是把它作为流处理的基础来使用，而且我们想要的正是进行reprocessing的模型。好奇的读者可以在这里找到更多关于卡夫卡的信息。 然而，从根本上说，没有任何东西把这个想法与Kafka联系起来，Kafka就是个日志系统而已。您可以用这个方法替换任何支持长期保留有序数据的系统（如HDFS）。实际上，很多人都熟悉类似的模式，即事件源或CQRS。当然，分布式数据库的人会告诉你，这只是实例化视图维护的一个rebranding，他们会很高兴地提醒你，他们很久以前就知道了，sonny。 七、比较Jay Kreps指出这种方法可以将Samza用作流处理系统，因为他们在LinkedIn上就是这么做的。但是Jay Kreps不知道它在Storm或其他流处理系统中不能同样有效的原因。“我对Storm不是很熟悉，所以我想知道其他人是否已经在这么做了”。无论如何，Jay Kreps认为总体思想是与系统无关的。是啊为什么呢 这两种方法之间的效率和资源权衡有点像wash。Lambda架构要求一直运行reprocessing和实时处理，而Jay Krep所建议的只需要在需要reprocessing时运行job的第二个副本。 但是，Jay Kreps的建议要求在输出数据库中暂时拥有2倍的存储空间，并且需要一个支持大容量写入的数据库来进行重新加载。在这两种情况下，重新处理的额外负荷可能会被平均化。如果您有很多这样的工作，它们将不会一次全部reprocess，因此在具有数十个这样的工作的共享群集上，您可以为可能会在任何给定时间进行reprocessing的少数工作预留额外的百分之几的容量。 Kafka真正的优势不在于效率，而在于允许人们在单一的处理框架上开发、测试、调试和操作他们的系统。因此，在简单性很重要的情况下，可以将此方法视为Lambda架构的替代方案。 启发维持两个系统同状态很难，那就只维持一个系统，另一个系统给它换成这个系统。为什么这个方法在Storm或其他流处理系统中不能同样有效有没有什么办法改进kappa对存储空间或大容量写入的要求替换方案不一定要全方位比原方法好，可以只考虑其中一个需求日志系统中删除的日志如何重计算 [1]Jay Kreps.Questioning the Lambda Architecture","permalink":"http://yimial.github.io/2019/11/12/Questioning%20the%20Lambda%20Architecture/","photos":[]},{"tags":[{"name":"Lambda 大数据处理框架","slug":"Lambda-大数据处理框架","permalink":"http://yimial.github.io/tags/Lambda-%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/"}],"title":"The Lambda architecture——principles for architecting realtime Big Data systems阅读笔记（翻译）","date":"2019/11/10","text":"query = function(all data)本文介绍了Lambda架构的三个层的任务和特点，最后就Lambda各个设定的意义展开了思考 一、引言Nathan Marz和James Warren合著的《大数据——可伸缩实时数据系统的原则和最佳实践》介绍了Lambda架构。Lambda是第一个真正将批处理和流处理协作解决无数用例的体系结构。 Lambda架构的前提：可以对所有数据运行ac-hoc查询来获得结果，但是这样做资源开销很大。 ac-hoc查询：即席查询是指那些用户在使用系统时，根据自己当时的需求定义的查询。 从技术上讲，现在对大数据运行ac-hoc查询(Cloudera Impala)是可行的，但在每次需要计算URL的页面访问量时查询pb级数据可能不是最有效的方法。因此，我们的想法是将结果预计算为一组视图，然后查询这些视图。 二、Lambda架构分为三个层次1.批处理层(Apache Hadoop)存储、计算 批处理层负责两件事。第一个是存储不可变的、不断增长的主数据集(HDFS)，第二个是从这个数据集计算任意视图(MapReduce)。 迭代计算 计算视图是一个持续的操作，当新数据到达时，它将在下一次MapReduce迭代的重计算过程中聚合到视图中。视图计算整个数据集，因此批处理层不需要频繁地更新视图。根据数据集和集群的大小，每次迭代可能需要几个小时。 2.服务层(Cloudera Impala)索引、Impala公开视图 批处理层的输出是一组包含预计算视图的平面文件。服务层负责索引和公开视图，以便查询。由于批处理视图是静态的，所以服务层只需要提供批量更新和随机读取功能，为此我们将使用Cloudera Impala。要使用Impala公开视图，服务层需要做的就是在Hive Metastore中创建一个指向HDFS文件的表（索引？）。用户将能够使用Impala立即查询视图。 12Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。Impala的定位是OLAP 引出速度层 Hadoop和Impala是批处理和服务层的完美工具。Hadoop可以存储和处理pb级的数据，Impala可以快速、交互式地查询这些数据。尽管如此，批处理和服务层本身并不满足任何实时需求，因为MapReduce(按设计)是高延迟的，可能需要几个小时才能在视图中表示新数据并将其传播到服务层。这就是为什么我们需要速度层。 请注意“实时”一词的用法。当作者说实时时，实际上作者指的是near-实时(NRT)，也就是事件发生与该事件的处理出任何数据之间的时间延迟。 12In the Lambda architecture, realtime is the ability to process the delta of data that has been captured after the start of the batch layers current iteration and now. 3.速度层增量，对应批处理层的迭代计算 本质上，速度层与批处理层相同，它也使用接收到的数据计算视图。但速度层需要补偿批处理层的高延迟，它通过在Storm中计算实时视图来达到这个目的。实时视图只包含对批处理视图进行补充的增量结果。批处理层从头开始不断地重新计算批处理视图，而速度层使用增量模型，当接收到新数据时，递增实时视图。 临时性，批处理层处理后即删除 临时性：speed层的聪明之处在于实时视图是瞬态的，一旦数据通过了批处理和服务层的处理，实时视图中的相应结果就可以丢弃。在书中，这被称为“复杂性隔离”，这意味着架构中最复杂的部分被推到结果是临时存在的层中。 Storm计算实时视图、HBase存储实时视图、Impala查询合并视图 最后一个难题是公开实时视图，以便对他们进行查询并与批处理视图合并，以获得完整的结果。由于实时视图是增量的，所以speed层需要随机读写，为此我们将使用Apache HBase。HBase为Storm提供了持续increment实时视图的能力，同时可以通过Impala查询与批处理视图的合并结果。Impala既可以查询存储在HDFS中的批处理视图，又可以查询存储在HBase中的实时视图，这使得它成为完成这项任务的完美工具。 三、思考Hadoop使得我们更方便地查询和更新数据。 不可变记录的意义 不可变记录（record）是一个记录在某一时刻的版本。可以添加记录的较新版本，但不能覆盖特定的版本，这意味着始终可以恢复到以前的状态。在Lambda架构中，这意味着如果您不小心添加了一些坏的记录，可以通过简单地删除这些记录，然后重新计算视图以修复问题。这本书把这个称为“human fault-tolerance” recompute的意义您可能会认为从头计算是一个bad idea，而且实现增量MapReduce算法来增加批处理视图更新的频率肯定会更有性能。尽管这样，你依然会牺牲性能来换取human fault-tolerance，因为在使用增量算法时，要修复视图中的任何问题都要困难得多。Storm层一般无法进行recompute，因为流处理层一般不保存数据，重现数据的增量计算很难 仅使用Hadoop生态系统能否实现相同的结果？（整个不懂，下次再学，总而言之兴许可以，但没必要）作者认为实现这种体系结构的原因在于您对实时的看法和需求，以及您是否认为human fault-tolerance是系统中的一个重要因素。在Hadoop中实现低延迟系统是可行的。例如，可以使用Apache Flume创建一个通到HDFS或HBase的ingest管道，并使用Impala查询数据。Flume的最新版本(1.2.0)还引入了拦截器的概念，可用于修改流数据。但Flume by design不是Storm那样的流媒体分析平台，因此作者认为很难在Flume中计算实时视图(但也不是不可能)。另一方面，Storm是一个专门构建的、可伸缩的流处理系统，它的延迟通常要低得多。 作者从大数据这本书(至少是前6章)中学到最多的是这个架构的原理。还有不变性和human fault-tolerance的重要性，以及预计算和重计算的好处。如果您正在考虑完整地实现Lambda架构，请问自己一个问题:我需要多实时?如果你的答案是在几十秒，那么完整的Lambda架构可能没有必要，但如果你的答案是毫秒，那么作者认为Lambda架构就是你的答案。 作为这篇文章的前导，作者一直在为Storm开发一个HBase连接器。连接器为在Lambda架构中创建实时视图提供了大量的Storm Bolt和Trident state的实现。 启发通过批处理视图迭代重计算+实时视图增量计算的方式，查询时拼接视图，使得系统架构可以更好的适用于这两种需求：满足容错性和实时性。 [1]James Kinley.The Lambda architecture——principles for architecting realtime Big Data systems[这篇博客的源博客的源博客：How to beat the CAP theorem]（http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html）","permalink":"http://yimial.github.io/2019/11/10/Lambda%20detail/","photos":[]}],"categories":[],"tags":[{"name":"比赛","slug":"比赛","permalink":"http://yimial.github.io/tags/%E6%AF%94%E8%B5%9B/"},{"name":"毕业","slug":"毕业","permalink":"http://yimial.github.io/tags/%E6%AF%95%E4%B8%9A/"},{"name":"Lambda 大数据","slug":"Lambda-大数据","permalink":"http://yimial.github.io/tags/Lambda-%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Lambda 大数据处理框架","slug":"Lambda-大数据处理框架","permalink":"http://yimial.github.io/tags/Lambda-%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6/"}]}