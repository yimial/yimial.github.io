<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.jpg">
  <link rel="icon" type="image/png" href="/img/favicon.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="执杭">
  <meta name="keywords" content="">
  <title>Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention论文笔记 - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>执杭</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/post.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2020-07-15 10:27">
      2020年7月15日 上午
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.1k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      32
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：2020年7月15日 下午
                
              </p>
            
            <article class="markdown-body">
              <blockquote>
<p>远程监督不可避免地会出现错误标注的问题，许多研究致力于从杂乱的数据中识别有效的实例。然而，在大多数现有方法中，每个关系都是单独处理的。对于每个关系，通常有一个单独的模型来从嘈杂的数据中选择关系相关的信息实例，而不考虑关系之间丰富的、通常以关系层次的形式存在的语义相关性。</p>
</blockquote>
<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>KG Freebase中就记录了很多关系间的层次，如 /location/province/capital和/location/location/contains和/location/country/capital之间就存在紧密的关系。为了充分利用关系之间丰富的相关信息，本文<strong>将关系的层次信息融入到远程监督关系提取中，提出了一种新的分层注意力方案</strong>，利用关系层次，但不是直接利用层次信息作为模型的特征。与传统的基于注意力的方法相似，本文的方法也根据每个实例在表达对应关系时的重要性计算一个注意力分数。关键的区别在于，本文的分层注意力方案遵循关系层次，在层次结构的每一层上计算那些包含相同实体对的实例的联合表示。</p>
<p><strong>分层注意方案提供了由粗到细的粒度，从而更好地识别有效实例，对提取长尾关系尤其有效。</strong></p>
<ul>
<li>底层的注意力可以捕获关系的更具体的特征，与传统的基于注意力的方法类似，它具有细粒度实例选择的能力。</li>
<li>顶层的注意力可以捕获几个由相关子关系共享的公共特征，从而提供粗粒度的实例选择能力。</li>
</ul>
<p>由于有足够的数据可用于训练顶层注意力，整个层次注意力方案可以增强模型对长尾关系的处理能力。</p>
<blockquote>
<p>出现频率较少的关系被称为长尾关系</p>
</blockquote>
<h3 id="相关研究"><a href="#相关研究" class="headerlink" title="相关研究"></a>相关研究</h3><p>关系层次揭示了关系之间丰富的相关性。事实上，McCallum等人(1998)已经利用类的层次结构来改进分类模型，并启发了许多后来的模型。此外，KGs中实体的层次信息也曾被利用，并已证明对模型增强有效。</p>
<p>与目前重点关注实体的层次结构和直接利用层次信息作为一个简单的特征的层次模型不同，本文结合了关系层次结构来构建一个从粗到细粒度的分层注意力方案，以提高RE性能。与现有的RE模型相比，本文的模型可以利用关系之间的相关性，更好地识别包含信息的实例，尤其是长尾关系，可以通过从与他们相关的高频关系中获取知识。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h4 id="符号表示"><a href="#符号表示" class="headerlink" title="符号表示"></a>符号表示</h4><p>KG表示为G = {E, R, F}，其中E, R, F分别表示实体、关系和实例的集合。</p>
<p>(h, r, t) ∈F表示h∈E和t∈E之间存在关系r∈R。</p>
<p>遵循MIL设置，将整个实例集拆分为多个实体对包{S<sub>h1,t1</sub>, S<sub>h2,t2</sub>，…}。每个包S<sub>hi,ti</sub>包含多个实例{s<sub>1</sub>, s<sub>2</sub>，…}，这些实例均同时提到实体h<sub>i</sub>和t<sub>i</sub>。远程监督机制将上述实体对的对应关系标注在包上。</p>
<p>这些包中的每个实例s都表示为一个单词序列s = {w<sub>1</sub>, w<sub>2</sub>， . .}。</p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>给定一个实体对(h, t)和它的实体对包S<sub>h,t</sub>，使用包中多个实例经过句子编码器和分层注意力机制对实体对进行建模，从而联合了多个实例的信息，采用该模型度量这个实体对表达各关系r的概率。该模型的总体框架包括一个句子编码器和一个从粗粒度到细粒度的分层注意力机制。</p>
<p>句子编码器采用多核卷积神经网络，使用embedding表示句子语义。再利用分层注意力机制选择信息最丰富的实例来准确表达它们之间的关系。</p>
<ul>
<li>对于每个实例s<sub>i</sub>∈S<sub>h,t</sub>，使用句子编码器将其语义信息表示为embedding s<sub>i</sub>。</li>
<li>由于包S<sub>h,t</sub>中并非所有的实例都是可表达h和t之间关系的正样本，本文应用分层注意力值来计算每个实例s<sub>i</sub>的实例权值α<sub>i</sub>。用实例embedding的加权和来建立全局文本关系表示r<sub>h,t</sub>，其中α<sub>i</sub>是第i个实例的embedding的权重，具体分层注意力计算方式之后详细介绍</li>
</ul>
<p>接下来估计r<sub>h,t</sub>对每个关系r∈R的概率，即h和t之间是否存在特定的r关系，其中o = Mr<sub>h,t</sub>，M是计算关系分数的表示矩阵。</p>
<h3 id="句子编码器"><a href="#句子编码器" class="headerlink" title="句子编码器"></a>句子编码器</h3><h4 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h4><p>句子编码器的输入层将单词的语义信息和相对位置信息嵌入到单词的输入embedding中</p>
<p>最后得到的单词w<sub>i</sub>的输入embedding为x<sub>i</sub>∈ R<sup>k<sub>i</sub></sup> (k<sub>i</sub> = k<sub>w</sub> + k<sub>p</sub> × 2)</p>
<h4 id="编码层"><a href="#编码层" class="headerlink" title="编码层"></a>编码层</h4><p>编码层的目的是将给定实例的输入embedding组成相应的实例embedding。选择CNN和maxpooling作为编码层的网络。反正分层注意力可以适应于各种编码架构。</p>
<p>PCNN的公式如下，它是采用卷积核来获得隐藏embedding；然后，对隐藏embedding应用分段最大池化，最后对各段embedding进行拼接。</p>
<h3 id="分层注意力机制"><a href="#分层注意力机制" class="headerlink" title="分层注意力机制"></a>分层注意力机制</h3><p>给定实体对(h, t)及其实例包S<sub>h,t</sub> = {s<sub>1</sub>, s<sub>2</sub>，…， s<sub>m</sub>}，使用句子编码器获得实例embedding {<strong>s<sub>1</sub>, s<sub>2</sub>，…， s<sub>m</sub></strong>}。然后对它们应用分层选择性注意力得到文本关系表示r<sub>h,t</sub>来提取关系。</p>
<p><strong>普通选择注意力机制</strong></p>
<p>q<sub>r</sub>：关系r的查询向量；W<sub>s</sub>：权重矩阵</p>
<p>将这种简单的选择注意力操作表示为如下方程</p>
<p><strong>分层选择注意力机制</strong></p>
<p>关系固有的层次结构自然地引导我们对层次注意进行建模。一般情况下，给定一个KG的关系集R，它由基层关系(如/location/province/capital)组成，由此可以生成相应的高层关系集R<sup>H</sup>。高层关系集中的关系(如位置)更为普遍，通常在基层集合中包含若干个子关系。</p>
<p>本文假设不同关系的子关系是不相交的，即关系层次是树形结构。那么生成过程可以递归地完成。在实践中，从集合R<sup>0</sup>=R（RE所关注的所有关系的集合）开始，经过k-1次生成来得到k级层次关系集{R<sup>0</sup>, R<sup>1</sup>，…, R<sup>k-1</sup>}。R<sup>0</sup>是最底层。</p>
<p>对于RE关注的关系r，通过回溯关系层次结构，构建其父关系层次链，其中r<sup>i-1</sup>是r<sup>i</sup>的子关系。</p>
<p>为每一层的每一个关系分配一个查询向量q<sub>r</sub>，根据关系层次链，计算每一层关系层次上的注意力操作，以获得相应的文本关系表示。</p>
<p>在训练过程中，高层关系的查询向量比基层关系的查询向量有更多的训练实例。因此，高层关系的查询向量在实例选择方面更健壮，但只提供粗粒度的选择能力。相比之下，基层查询向量往往存在数据稀疏性问题，特别是长尾的基层关系。因此，基层查询向量可以执行细粒度的实例选择，但性能不稳定。</p>
<p>基于分层选择性注意力，简单地将不同的层上的文本关系表示进行拼接作为最终表示。</p>
<p>最后，r<sub>h,t</sub>会被用于计算条件概率P(r|h, t, S<sub>h,t</sub>)</p>
<p>高层次表示是粗粒度的，基层次表示是细粒度的。相比单层注意力，这种分层表示对于关系预测，特别是对长尾关系的预测，提供了更多的信息。</p>
<h3 id="其他设置"><a href="#其他设置" class="headerlink" title="其他设置"></a>其他设置</h3><p>损失函数选择带有L2正则化的交叉熵损失函数，所有模型均采用随机梯度下降法进行优化</p>
<p>对于CNN，将dropout设置为0.5。对于PCNN，由于观察到该模型很快就会对训练集进行过拟合，因此将dropout设置为0.9来缓解过拟合问题。在对分层注意力进行训练之前，还对PCNN的句子编码器进行了预训练。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="总体评估结果"><a href="#总体评估结果" class="headerlink" title="总体评估结果"></a>总体评估结果</h3><ul>
<li>在查全率小于0.05时，所有方法均有合理的精度。当查全率逐渐增加时，基于特征的方法的性能下降速度要比神经模型快得多。这表明，与神经模型相比，人工设计的特征非常有限，特别是在有噪声的数据中。因此，为了简单起见，在接下来的实验中主要展示本文模型和其他基于注意力的神经模型的结果</li>
<li>有注意力方案的模型优于没有注意力方案的普通模型。虽然传统的神经模型对于关系分类是强大的，但它仍然很难解决数据噪声的问题。基于注意力的方法将注意力应用在多个实例上，动态地减少实例噪声的影响，可以有效地提高RE的性能。</li>
<li>与传统的独立处理每个关系的普通注意力方案相比，本文的方法能更好地利用关系之间丰富的相关性。且分级注意力方案的性能可以通过采用额外的机制，如对抗性训练、强化学习和实体对级别的软标记来进一步提高。</li>
</ul>
<h3 id="等级注意对不同关系的影响"><a href="#等级注意对不同关系的影响" class="headerlink" title="等级注意对不同关系的影响"></a>等级注意对不同关系的影响</h3><p>作为precision-recall 曲线下面积的近似值，微平均给出了更完整的模型性能的视图。由于微平均通常忽略了那些长尾关系的影响，所以本文使用宏平均来更加强调测试集中的长尾关系，这一点在之前的工作中经常被忽略。</p>
<blockquote>
<p><a href="https://www.chzzz.club/post/123.html" target="_blank" rel="noopener">微平均和宏平均</a></p>
</blockquote>
<p>从微观和宏观的平均精度来看，本文的HATT方法有效地提高了RE的性能，特别是对于那些长尾关系。</p>
<p>为了进一步证明在长尾关系性能上的改善，本文使用Hits@K方法进行评估。即对于每一个实体对，评估在模型得到的前K个候选关系中是否有对应的真实关系。由于现有模型难以提取长尾关系，本文设K为{10,15,20}。</p>
<p><strong>评估结论</strong>：</p>
<ul>
<li>对于CNN和PCNN模型，分层注意模型优于普通注意模型。通过利用关系层次，本文模型可以通过关系之间的关联信息更好地学习长尾关系。</li>
<li>CNN模型比普通的PCNN模型有更好的性能。这显示了关系层次结构的威力，它使得简单的CNN模型在长尾关系方面优于PCNN模型。</li>
<li>虽然HATT方法在长尾关系方面与普通的ATT方法相比取得了明显的进展，但这些方法的结果都不尽人意。这说明，远程监督关系抽取不仅存在错误标识问题，还存在长尾关系问题。</li>
</ul>
<h3 id="不同实例对分层注意的影响"><a href="#不同实例对分层注意的影响" class="headerlink" title="不同实例对分层注意的影响"></a>不同实例对分层注意的影响</h3><p>one测试集：为每个实体对随机选择一个实例进行评估的测试集</p>
<p>two测试集：为每个实体对随机选择两个实例的测试集</p>
<p>all测试集：对每个剩余实体对的所有实例进行评估</p>
<p>对于one和one测试集的对比，想说明的是考虑关系之间的相关信息可以得到更好的关系分类器。</p>
<p>ALL测试集旨在显示分层注意力对多实例方法的影响。</p>
<p><strong>结果</strong>：</p>
<ul>
<li>所有方法的性能基本都会随着实例数量的增加而提高。这表明，选择性注意模型可以通过合并有用的实例，剔除无用的实例，有效地利用来自多个噪声实例的信息。</li>
<li>HATT方法在one测试集中也具有较高的精度值，这说明即使在信息不足的情况下，本文的分层注意力也可以捕捉到关系之间的相关性。</li>
</ul>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</a>
                    
                      <a class="hover-with-bg" href="/tags/%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3/">远程监督</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%A4%9A%E5%AE%9E%E4%BE%8B/">多实例</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%88%86%E5%B1%82%E6%B3%A8%E6%84%8F%E5%8A%9B/">分层注意力</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/07/15/AdvDS/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Adversarial Training for Relation Extraction论文笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/07/14/classtie/">
                        <span class="hidden-mobile">Jointly extracting relations with class ties via effective deep ranking论文笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "KFUt1PtYt65wARildGEwd2Wc-gzGzoHsz",
          app_key: "H1drDYV5zLpzLpyzCOP4moVf",
          placeholder: "请讲",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: true,
          serverURLs: "https://kfut1pty.lc-cn-n1-shared.com",
        });
      });
    }
    createObserver(loadValine, 'vcomments');
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention论文笔记&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>




















</body>
</html>
