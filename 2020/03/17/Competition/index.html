<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="baidu-site-verification" content="vvVgSQUzPU" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1"
    />
    <meta name="keywords" content="虎虎|博客|个人|utone|Utone|">
    <meta name="description" content="骑士恨煎蛋，骑士恨孜然">
    
    <title>
       双准备参加比赛（这次要认真走完 -  Hexo
    </title>
    
<link rel="stylesheet" href="/css/style.css">
 
    
      <link rel="icon" href="/images/favicon.ico" />
    
  <meta name="generator" content="Hexo 4.2.1"></head>
  <body>
    <div id="container">
      <div id="main-left">
        <div id="introduce">
          <div class="logo-worp">
            <a href="/"><img class="logo" src="/images/logo.png" alt=""/></a>
          </div>
          <ul>
            
              <li><a href="/"> Home </a></li>
            
              <li><a href="/archives"> Archive </a></li>
            
              <li><a href="/about"> About </a></li>
            
              <li><a href="/atom.xml"> RSS </a></li>
            
            <li>
              <img id="search-img" src="/images/search.svg" alt="search" />
            </li>
          </ul>
           
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#前期准备"><span class="post-toc-number">1.</span> <span class="post-toc-text">前期准备</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#transformer学习（3-15-3-17）"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">transformer学习（3.15-3.17）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#bert学习（3-17-）"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">bert学习（3.17-）</span></a></li></ol></li></ol> 
          
        </div>
      </div>
      <div id="main-right"><div id="post">
    
    <header class="article-header">
        <h1>
            双准备参加比赛（这次要认真走完
        </h1>
    </header>
    
    <div class="post-meta">
        <time class="post-data" datetime="2020-03-17T14:38:14.000Z" itemprop="datePublished">
            2020-03-17
        </time>
        
        
        <ul class="post-tag-list" itemprop="keywords"><li class="post-tag-list-item"><a class="post-tag-list-link" href="/tags/hide/" rel="tag">hide</a><span class="post-tag-list-count">6</span></li></ul>
        
    </div>
    
    <div class="post-entry">
        <p>##疫情期间情绪分析比赛</p>
<p>同样研究nlp方向的朋友来找我一起参加比赛，我也正有此意，于是开始着手准备。</p>
<h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><p>准备参加比赛的时候我的nlp学习进度才进行到acnn……为了能参加比赛，跳级先学transformer、bert等（果然跳级需谨慎）。</p>
<h4 id="transformer学习（3-15-3-17）"><a href="#transformer学习（3-15-3-17）" class="headerlink" title="transformer学习（3.15-3.17）"></a>transformer学习（3.15-3.17）</h4><p>这个我是直接看的论文，很多地方没看懂，于是看了一个超级简单的代码，代码省略了很多细节，又看了一篇朋友推荐的博客才看懂<br><a href="https://www.cnblogs.com/anai/p/11572847.html" target="_blank" rel="noopener">想研究BERT模型？先看看这篇文章吧！</a><br>对所谓seq2seq有了一些了解，之前师兄一直说到的transformer原来是这样的。</p>
<h4 id="bert学习（3-17-）"><a href="#bert学习（3-17-）" class="headerlink" title="bert学习（3.17-）"></a>bert学习（3.17-）</h4><p>从下文开始入门的bert，上来就点进去第一个链接看了bert的github。。。。。。没看明白。。。。。<br>    <a href="https://blog.csdn.net/sunhua93/article/details/102764783" target="_blank" rel="noopener">一文读懂BERT(原理篇)</a><br>于是还是打算从下面的blog结合论文和最简单的代码开始看吧<br>    <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" target="_blank" rel="noopener">Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing</a><br>从以上找到几个不错的代码，下面这个可以用于情感分析<br>    <a href="https://github.com/brightmart/sentiment_analysis_fine_grain" target="_blank" rel="noopener">BERT实战，多标签文本分类，在 AI Challenger 2018 细粒度情感分析任务上的尝试</a><br>下面这个是不是可以为我毕设所用嘿嘿嘿<br>    <a href="https://github.com/kyzhouhzau/BERT-NER" target="_blank" rel="noopener">BERT实战，命名实体识别</a><br>    <a href="https://github.com/nocater/Entity-Relation-Extraction" target="_blank" rel="noopener">BERT实体与关系抽取</a><br>看完了论文和blog，发现官方源码看不懂，于是找了一些csdn和知乎上的讲解<br>    <a href="https://blog.csdn.net/minzhimo4854/article/details/93887427" target="_blank" rel="noopener">bert的使用</a><br>    <a href="https://cloud.tencent.com/developer/article/1424707" target="_blank" rel="noopener">bert的花式改进</a><br>没有TPU的时候可以把tpu改成gpu<br>    <a href="https://blog.csdn.net/ling620/article/details/97789853" target="_blank" rel="noopener">代码简化</a><br>这个代码给了我启发，我是不是也可以用bert的预训练结果用于训练lstm-attention等网络，然后再做xgboost<br>    <a href="https://github.com/nlpjoe/CCF-BDCI-Automotive-Field-ASC-2018" target="_blank" rel="noopener">CCF-BDCI2018 汽车领域ASC挑战赛</a></p>

    </div>
    <!--畅言PC和WAP自适应版-->
  
</div></div>
    </div>
    <div id="footer">骑士恨煎蛋，骑士恨孜然</div>
    <img id="top" src="/images/up-circle.svg" alt="top" />
    
  </body>
</html>
<!-- 加载主题脚本文件 -->

<script src="/scripts/utone.js"></script>


<script type="text/javascript">
  window.onload = function() {
    scroll.init()
    siteSearch.init()
  }
</script>
